"""
Clonage vocal avec Chatterbox Multilingual (Resemble AI).
Supporte 23 langues dont le fran√ßais. MIT License.
"""
import torch
import torchaudio as ta
from pathlib import Path


class VoiceCloner:
    """Clone une voix √† partir d'un √©chantillon audio de 3-15 secondes."""

    SUPPORTED_LANGUAGES = [
        "ar", "da", "de", "el", "en", "es", "fi", "fr", "he", "hi",
        "it", "ja", "ko", "ms", "nl", "no", "pl", "pt", "ru", "sv",
        "sw", "tr", "zh",
    ]

    def __init__(self, device: str = "auto"):
        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
        self._model = None

    @property
    def model(self):
        """Lazy loading du mod√®le Chatterbox Multilingual."""
        if self._model is None:
            from chatterbox.tts import ChatterboxMultilingualTTS
            print(f"‚è≥ Chargement Chatterbox Multilingual ({self.device})...")
            self._model = ChatterboxMultilingualTTS.from_pretrained(device=self.device)
            print("‚úÖ Mod√®le vocal charg√© !")
        return self._model

    def generate(
        self,
        text: str,
        voice_sample_path: str,
        output_path: str,
        language: str = "fr",
        exaggeration: float = 0.5,
        cfg_weight: float = 0.5,
    ) -> str:
        """
        G√©n√®re un audio avec la voix clon√©e.

        Args:
            text: Texte √† synth√©tiser
            voice_sample_path: √âchantillon audio de r√©f√©rence (3-15s, WAV)
            output_path: Chemin de sortie (.wav)
            language: Code ISO langue (fr, en, es, de...)
            exaggeration: Expressivit√© (0.0=monotone ‚Üí 1.5=tr√®s expressif)
            cfg_weight: Fid√©lit√© texte (0.3=naturel ‚Üí 0.7=fid√®le)

        Returns:
            Chemin du fichier audio g√©n√©r√©
        """
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        print(f"üéôÔ∏è G√©n√©ration vocale [{language}] : {text[:60]}...")

        wav = self.model.generate(
            text,
            audio_prompt_path=voice_sample_path,
            language_id=language,
            exaggeration=exaggeration,
            cfg_weight=cfg_weight,
        )

        ta.save(output_path, wav, self.model.sr)
        print(f"‚úÖ Audio : {output_path}")
        return output_path
